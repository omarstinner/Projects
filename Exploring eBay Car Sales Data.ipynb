{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring eBay Car Listings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "> \"eBay Kleineanzeigen\" translated into English as \"eBay Small ads\", is a German Marketplace where users can find great deals from household goods to clothing, garden tools, electronics, and second-hand items. More interestingly, it's a popular platform for selling cars. Throughout this project, we will be working with a dataset that has over 50,000 used cars. The aim of this project is to clean the various columns of the dataset and explore the different characters of used cars in this marketplace. The first part of this notebook will focus on preparing and cleaning the dataset for exploration, while the second part will center on exploring the cleaned data and discovering interesting findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from tabulate import tabulate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the dataset\n",
    "autos = pd.read_csv(\"/Users/omarstinner/Data Files/Python Projects/Files/Guided Project - Exploring eBay Car Sales Data/autos.csv\", encoding = \"Latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 20 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   dateCrawled          50000 non-null  object\n",
      " 1   name                 50000 non-null  object\n",
      " 2   seller               50000 non-null  object\n",
      " 3   offerType            50000 non-null  object\n",
      " 4   price                50000 non-null  object\n",
      " 5   abtest               50000 non-null  object\n",
      " 6   vehicleType          44905 non-null  object\n",
      " 7   yearOfRegistration   50000 non-null  int64 \n",
      " 8   gearbox              47320 non-null  object\n",
      " 9   powerPS              50000 non-null  int64 \n",
      " 10  model                47242 non-null  object\n",
      " 11  odometer             50000 non-null  object\n",
      " 12  monthOfRegistration  50000 non-null  int64 \n",
      " 13  fuelType             45518 non-null  object\n",
      " 14  brand                50000 non-null  object\n",
      " 15  notRepairedDamage    40171 non-null  object\n",
      " 16  dateCreated          50000 non-null  object\n",
      " 17  nrOfPictures         50000 non-null  int64 \n",
      " 18  postalCode           50000 non-null  int64 \n",
      " 19  lastSeen             50000 non-null  object\n",
      "dtypes: int64(5), object(15)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "autos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Before cleaning and exploring our data, letâ€™s first get a macro overview of our dataset as a whole and take a look at some of the characteristics of our columns. Looking at the output above, we see that the \"vehicleType\", \"gearbox\", \"model\", \"fueltype\", and \"notRepairDamage\" columns all include null values. However, none of these columns have more than 20% null values. We can also tell that the following columns have been assigned the wrong data type: \"dateCrawled\", \"price\", \"odometer\", \"dateCreated\", and \"lastSeen\". This is mostly due to the addition of symbols to the column contents such as \"$\" (for price) and \"km\" (for odometer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Cleaning The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos.columns = ['date_crawled', 'name', 'seller', 'offer_type', 'price', 'ab_test',\n",
    "       'vehicle_type', 'registration_year', 'gearbox', 'power_ps', 'model',\n",
    "       'odometer', 'registration_month', 'fuel_type', 'brand',\n",
    "       'unrepaired_damage', 'ad_created', 'nr_of_pictures', 'postal_code',\n",
    "       'last_seen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **What's Happening?** We are changing the column names from camel case to snake case because using snake case has a cleaner appearance and is regarded as the standard case for naming columns in python. We are also rewording some of the columns for a more fitting description of the column's contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_crawled</th>\n",
       "      <th>name</th>\n",
       "      <th>seller</th>\n",
       "      <th>offer_type</th>\n",
       "      <th>price</th>\n",
       "      <th>ab_test</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>registration_year</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power_ps</th>\n",
       "      <th>model</th>\n",
       "      <th>odometer</th>\n",
       "      <th>registration_month</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>unrepaired_damage</th>\n",
       "      <th>ad_created</th>\n",
       "      <th>nr_of_pictures</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>last_seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "      <td>44905</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>47320</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>47242</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>45518</td>\n",
       "      <td>50000</td>\n",
       "      <td>40171</td>\n",
       "      <td>50000</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>48213</td>\n",
       "      <td>38754</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2357</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>245</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2016-03-11 22:38:16</td>\n",
       "      <td>Ford_Fiesta</td>\n",
       "      <td>privat</td>\n",
       "      <td>Angebot</td>\n",
       "      <td>$0</td>\n",
       "      <td>test</td>\n",
       "      <td>limousine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>manuell</td>\n",
       "      <td>NaN</td>\n",
       "      <td>golf</td>\n",
       "      <td>150,000km</td>\n",
       "      <td>NaN</td>\n",
       "      <td>benzin</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>nein</td>\n",
       "      <td>2016-04-03 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-04-07 06:17:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>49999</td>\n",
       "      <td>49999</td>\n",
       "      <td>1421</td>\n",
       "      <td>25756</td>\n",
       "      <td>12859</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4024</td>\n",
       "      <td>32424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30107</td>\n",
       "      <td>10687</td>\n",
       "      <td>35232</td>\n",
       "      <td>1946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2005.073280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.355920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.723360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50813.627300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.712813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>209.216627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.711984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25779.747957</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1067.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30451.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49577.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71540.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17700.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99998.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date_crawled         name  seller offer_type  price ab_test  \\\n",
       "count                 50000        50000   50000      50000  50000   50000   \n",
       "unique                48213        38754       2          2   2357       2   \n",
       "top     2016-03-11 22:38:16  Ford_Fiesta  privat    Angebot     $0    test   \n",
       "freq                      3           78   49999      49999   1421   25756   \n",
       "mean                    NaN          NaN     NaN        NaN    NaN     NaN   \n",
       "std                     NaN          NaN     NaN        NaN    NaN     NaN   \n",
       "min                     NaN          NaN     NaN        NaN    NaN     NaN   \n",
       "25%                     NaN          NaN     NaN        NaN    NaN     NaN   \n",
       "50%                     NaN          NaN     NaN        NaN    NaN     NaN   \n",
       "75%                     NaN          NaN     NaN        NaN    NaN     NaN   \n",
       "max                     NaN          NaN     NaN        NaN    NaN     NaN   \n",
       "\n",
       "       vehicle_type  registration_year  gearbox      power_ps  model  \\\n",
       "count         44905       50000.000000    47320  50000.000000  47242   \n",
       "unique            8                NaN        2           NaN    245   \n",
       "top       limousine                NaN  manuell           NaN   golf   \n",
       "freq          12859                NaN    36993           NaN   4024   \n",
       "mean            NaN        2005.073280      NaN    116.355920    NaN   \n",
       "std             NaN         105.712813      NaN    209.216627    NaN   \n",
       "min             NaN        1000.000000      NaN      0.000000    NaN   \n",
       "25%             NaN        1999.000000      NaN     70.000000    NaN   \n",
       "50%             NaN        2003.000000      NaN    105.000000    NaN   \n",
       "75%             NaN        2008.000000      NaN    150.000000    NaN   \n",
       "max             NaN        9999.000000      NaN  17700.000000    NaN   \n",
       "\n",
       "         odometer  registration_month fuel_type       brand unrepaired_damage  \\\n",
       "count       50000        50000.000000     45518       50000             40171   \n",
       "unique         13                 NaN         7          40                 2   \n",
       "top     150,000km                 NaN    benzin  volkswagen              nein   \n",
       "freq        32424                 NaN     30107       10687             35232   \n",
       "mean          NaN            5.723360       NaN         NaN               NaN   \n",
       "std           NaN            3.711984       NaN         NaN               NaN   \n",
       "min           NaN            0.000000       NaN         NaN               NaN   \n",
       "25%           NaN            3.000000       NaN         NaN               NaN   \n",
       "50%           NaN            6.000000       NaN         NaN               NaN   \n",
       "75%           NaN            9.000000       NaN         NaN               NaN   \n",
       "max           NaN           12.000000       NaN         NaN               NaN   \n",
       "\n",
       "                 ad_created  nr_of_pictures   postal_code            last_seen  \n",
       "count                 50000         50000.0  50000.000000                50000  \n",
       "unique                   76             NaN           NaN                39481  \n",
       "top     2016-04-03 00:00:00             NaN           NaN  2016-04-07 06:17:27  \n",
       "freq                   1946             NaN           NaN                    8  \n",
       "mean                    NaN             0.0  50813.627300                  NaN  \n",
       "std                     NaN             0.0  25779.747957                  NaN  \n",
       "min                     NaN             0.0   1067.000000                  NaN  \n",
       "25%                     NaN             0.0  30451.000000                  NaN  \n",
       "50%                     NaN             0.0  49577.000000                  NaN  \n",
       "75%                     NaN             0.0  71540.000000                  NaN  \n",
       "max                     NaN             0.0  99998.000000                  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    50000\n",
      "Name: nr_of_pictures, dtype: int64\n",
      "10115    109\n",
      "65428    104\n",
      "66333     54\n",
      "45888     50\n",
      "44145     48\n",
      "        ... \n",
      "71576      1\n",
      "76776      1\n",
      "76872      1\n",
      "91233      1\n",
      "67585      1\n",
      "Name: postal_code, Length: 7014, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Looking at the descriptive statistics for all the columns\n",
    "display(autos.describe(include = \"all\"))\n",
    "\n",
    "# Further insepcting the \"nr_of_pictures\" and \"postal_code\" columns\n",
    "print(autos[\"nr_of_pictures\"].value_counts())\n",
    "print(autos[\"postal_code\"].value_counts())\n",
    "\n",
    "# Dropping the columns \"seller\", \"offer_type\", \"num_photos\"\n",
    "autos = autos.drop([\"seller\", \"offer_type\", \"nr_of_pictures\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **What's Happening?** We are looking at descriptive statistics of the dataset to look for column candidates we can remove entirely. The columns that are in contention of being dropped are \"seller\" and \"offer_type\". Mainly because they both only have 2 unique values of which 49,999 of the columns are the same. \"ab_test\", \"gear_box\", and \"unrepaired_damage\" also only have 2 unique values, however, the split of the rows between the unique values in the columns are more distributed. The \"nr_of_pictures\" and \"postal_code\" columns also look quite odd, with the output telling us they have \"NaN\" values for the \"unique\" and \"top\" criteria. After further exploration into the columns, we see that only \"nr_of_pictures\" warrants a drop as all the values in the column are 0, while the \"postal code\" column has multiple unique values that could be useful to us in our analysis, and so we will keep the column. After better understanding the columns mentioned in this cell, we have proceeded and dropped \"seller\", \"offer_type\", and \"nr_of_pictures\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting\"vehicle_type\" column to english\n",
    "autos[\"vehicle_type\"] = autos[\"vehicle_type\"].str.replace(\"kleinwagen\",\"minature car\")\n",
    "autos[\"vehicle_type\"] = autos[\"vehicle_type\"].str.replace(\"kombi\",\"station wagon\")\n",
    "autos[\"vehicle_type\"] = autos[\"vehicle_type\"].str.replace(\"andere\",\"other\")\n",
    "\n",
    "# Converting\"gearbox\" column to english\n",
    "autos[\"gearbox\"] = autos[\"gearbox\"].str.replace(\"manuell\", \"manual\")\n",
    "autos[\"gearbox\"] = autos[\"gearbox\"].str.replace(\"automatik\", \"automatic\")\n",
    "\n",
    "# Converting \"fuel_type\" column to english\n",
    "fuel_type_dict = {\"lpg\" : \"lpg\",\n",
    "                 \"benzin\" : \"petrol\",\n",
    "                 \"diesel\" : \"diesel\",\n",
    "                 \"nan\" : \"nan\",\n",
    "                 \"cng\" : \"cng\",\n",
    "                 \"hybrid\" : \"hybrid\",\n",
    "                 \"elektro\" : \"electric\",\n",
    "                 \"andere\" : \"other\"}\n",
    "autos[\"fuel_type\"] = autos[\"fuel_type\"].map(fuel_type_dict)\n",
    "\n",
    "# Converting \"unrepaired_damage\" column to english\n",
    "unrepaired_damage_dict = {\"nein\" : \"no\",\n",
    "                         \"ja\" : \"yes\",\n",
    "                         \"nan\" : \"nan\"}\n",
    "autos[\"unrepaired_damage\"] = autos[\"unrepaired_damage\"].map(unrepaired_damage_dict)\n",
    "\n",
    "# Converting \"model\" column to english\n",
    "autos[\"model\"] = autos[\"model\"].str.replace(\"andere\", \"other\")\n",
    "autos[\"model\"] = autos[\"model\"].str.replace(\"_reihe\", \"_series\")\n",
    "autos.loc[(autos[\"brand\"] == \"bmw\") & (autos[\"model\"].str[-2:] == \"er\"), \"model\"] = autos.loc[(autos[\"brand\"] == \"bmw\") & (autos[\"model\"].str[-2:] == \"er\"), \"model\"].str.replace(\"er\", \"_series\")\n",
    "autos[\"model\"] = autos[\"model\"].str.replace(\"klasse\", \"class\")\n",
    "autos[\"model\"] = autos[\"model\"].str.replace(\"oth_series\", \"other\")\n",
    "\n",
    "# Converting the \"brand\" column to english\n",
    "autos[\"brand\"] = autos[\"brand\"].str.replace(\"sonstige_autos\", \"miscellaneous_cars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **What's Happening?** The columns \"vehicle_type\", \"gearbox\", \"fuel_type\", \"unrepaired_damages\", and \"model\" are all in German and so we are translating the columns to english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1421\n",
      "500      781\n",
      "1500     734\n",
      "2500     643\n",
      "1000     639\n",
      "1200     639\n",
      "600      531\n",
      "800      498\n",
      "3500     498\n",
      "2000     460\n",
      "999      434\n",
      "750      433\n",
      "900      420\n",
      "650      419\n",
      "850      410\n",
      "700      395\n",
      "4500     394\n",
      "300      384\n",
      "2200     382\n",
      "950      379\n",
      "Name: price, dtype: int64\n",
      "(2357,)\n",
      "99999999       1\n",
      "27322222       1\n",
      "12345678       3\n",
      "11111111       2\n",
      "10000000       1\n",
      "            ... \n",
      "5              2\n",
      "3              1\n",
      "2              3\n",
      "1            156\n",
      "0           1421\n",
      "Name: price, Length: 2357, dtype: int64\n",
      "99999999\n",
      "99999999    1\n",
      "27322222    1\n",
      "12345678    3\n",
      "11111111    2\n",
      "10000000    1\n",
      "3890000     1\n",
      "1300000     1\n",
      "1234566     1\n",
      "999999      2\n",
      "999990      1\n",
      "350000      1\n",
      "345000      1\n",
      "299000      1\n",
      "295000      1\n",
      "265000      1\n",
      "259000      1\n",
      "250000      1\n",
      "220000      1\n",
      "198000      1\n",
      "197000      1\n",
      "Name: price, dtype: int64\n",
      "111       2\n",
      "110       3\n",
      "100     134\n",
      "99       19\n",
      "90        5\n",
      "89        1\n",
      "80       15\n",
      "79        1\n",
      "75        5\n",
      "70       10\n",
      "66        1\n",
      "65        5\n",
      "60        9\n",
      "59        1\n",
      "55        2\n",
      "50       49\n",
      "49        4\n",
      "47        1\n",
      "45        4\n",
      "40        6\n",
      "35        1\n",
      "30        7\n",
      "29        1\n",
      "25        5\n",
      "20        4\n",
      "18        1\n",
      "17        3\n",
      "15        2\n",
      "14        1\n",
      "13        2\n",
      "12        3\n",
      "11        2\n",
      "10        7\n",
      "9         1\n",
      "8         1\n",
      "5         2\n",
      "3         1\n",
      "2         3\n",
      "1       156\n",
      "0      1421\n",
      "Name: price, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Removing Symbols from the \"price\" column\n",
    "autos[\"price\"] = autos[\"price\"].str.replace(\",\", \"\")\n",
    "autos[\"price\"] = autos[\"price\"].str.replace(\"$\", \"\").astype(\"int64\")\n",
    "\n",
    "# Removing Symbols from the \"odometer\" column\n",
    "autos[\"odometer\"] = autos[\"odometer\"].str.replace(\",\",\"\")\n",
    "autos[\"odometer\"] = autos[\"odometer\"].str.replace(\"km\",\"\").astype(\"int64\")\n",
    "autos.rename({\"odometer\" : \"odometer_km\"}, axis = 1, inplace = True)\n",
    "\n",
    "print(autos[\"price\"].value_counts().head(20))\n",
    "print(autos[\"price\"].unique().shape)\n",
    "print(autos[\"price\"].value_counts().sort_index(ascending = False))\n",
    "print(autos[\"price\"].max())\n",
    "print(autos[\"price\"].value_counts().sort_index(ascending = False).head(20))\n",
    "print(autos[\"price\"].value_counts().sort_index(ascending = False).tail(40))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **What's Happening?** Here we are cleaning the \"price\" and \"odometer_km\" columns. We remove the \",\" symbol from both columns, the \"\\\\$\" symbol from the \"price\" column, and the \"km\" symbol from the \"odometer_km\" for computation purposes. We then are further examined the \"price\" column to identify rows that are inaccurate. We can see that there are 1421 cars that are priced at $0, which does not seem accurate as people would not sell their cars for anything. We also see car listings that are priced above \\\\$1 million, which is also hard to believe. There are in fact some cars priced this high, however, these types of sales do not usually occur on eBay, but rather at a more formal setting, such as an auction house. For these reasons, we will remove such outliers in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows before removing outliers:  50000\n",
      "number of rows after removing outliers:  48364\n",
      "===========  ================  =======  =============  =============\n",
      "column       outliers (T/F)      count    lower limit    upper limit\n",
      "===========  ================  =======  =============  =============\n",
      "price        True                 1636              1          49450\n",
      "odometer_km  False                   0              1         330000\n",
      "===========  ================  =======  =============  =============\n"
     ]
    }
   ],
   "source": [
    "# Creating a function that detects outliers and removes them\n",
    "def outlier_remover(df, cols_list, change = False):\n",
    "    data = []\n",
    "    index_list = []\n",
    "    print(\"number of rows before removing outliers: \", df.shape[0])\n",
    "    for col in cols_list:\n",
    "        # Defining the upper and lower limits for outlier detection\n",
    "        q1 = df[col].quantile(0.05)\n",
    "        q3 = df[col].quantile(0.95)\n",
    "        iqr = q3 - q1\n",
    "        \n",
    "        upper_limit = q3 + 1.5 * iqr\n",
    "        lower_limit = q1 - 1.5 * iqr\n",
    "        \n",
    "        # If the lower_limit is below 0 then I decided to to make the lower_limit the half way point between 25th percentile and the minimum value, so that I could be reasonably inclusive\n",
    "        if lower_limit < 0:\n",
    "            lower_limit = 1\n",
    "        \n",
    "        # Finding out whether or not a column has outliers and seeing how many outliers are present in the column \n",
    "        true_or_false = None\n",
    "        count = None\n",
    "        if df[(df[col] < lower_limit) | (df[col] > upper_limit)].any(axis = None):#Im guessing the above evausates to weather there are any rows present, adn there are, so it evaluates to true\n",
    "            true_or_false = True\n",
    "            count = df[(df[col] < lower_limit) | (df[col] > upper_limit)].shape[0]\n",
    "            # Adding to the index_list the index label/number of the row that has an outlier\n",
    "            index_list.extend(list(df[(df[col] < lower_limit) | (df[col] > upper_limit)].index))\n",
    "        else:\n",
    "            true_or_false = False\n",
    "            count = 0\n",
    "            \n",
    "        \n",
    "        # Append to the data list\n",
    "        data.append([col, true_or_false, count, lower_limit, upper_limit])\n",
    "    \n",
    "    # Making sure that the same index labels/numbers aren't repeated\n",
    "    index_list = list(set(index_list))\n",
    "\n",
    "    # Removing the rows deemed outliers\n",
    "    if change:\n",
    "        df = df.drop(index_list)\n",
    "        \n",
    "    \n",
    "    table = tabulate(data, headers = [\"column\", \"outliers (T/F)\", \"count\", \"lower limit\", \"upper limit\" ], tablefmt = \"rst\", numalign = \"right\")\n",
    "    print(\"number of rows after removing outliers: \", df.shape[0])\n",
    "    print(table)\n",
    "    return df\n",
    "\n",
    "# Removing outliers from both the \"price\" and \"odometer_km\" column\n",
    "autos = outlier_remover(autos, [\"price\", \"odometer_km\"], change = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **What's Happening?** We created a function that detects outliers that remove such identified rows. To ensure that car listings priced at $0 and having an odometer reading of 0 km are not included, we set the outlier lower limit to 1. The output of the function is a table that shows us whether a column has outliers or not, the number of outliers present in the column, and the lower and upper outlier limits. We see that the \"price\" column had 1636 outliers, but the \"odometer_km\" did not. We have used the function to remove such rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the data type of the date related columns to a dateitime object\n",
    "autos[\"date_crawled\"] = pd.to_datetime(autos[\"date_crawled\"])\n",
    "autos[\"ad_created\"] = pd.to_datetime(autos[\"ad_created\"])\n",
    "autos[\"last_seen\"] = pd.to_datetime(autos[\"last_seen\"])\n",
    "\n",
    "# Only selecting rows where registration_year is between 1900 and 2016\n",
    "autos = autos[autos[\"registration_year\"].between(1900,2016)]\n",
    "\n",
    "# Creating a new column\n",
    "autos[\"registration_month+year\"] = (\"0\" + autos[\"registration_month\"].astype(str) + \"-\" + autos[\"registration_year\"].astype(str)).str[-7:]\n",
    "autos[autos[\"registration_month+year\"].str[:2] == \"00\"] = np.nan\n",
    "autos[\"registration_month+year\"] = pd.to_datetime(autos[\"registration_month+year\"], format = \"%m-%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **What's Happening?** We are converting the \"date_crawled\", \"ad_created\", and \"last\" seen column into datetime objects. Since the year in which a car is last seen is 2016, it is impossible to have car registration past the latest \"last seen\" date. For that reason, we have selected only a listing with registration dates between 1900 and 2016. Although selecting such rows has immensely cleaned our data, we still need to deal with listings where cars have registration dates past last seen dates in 2016. This means we need to compare the two dates on a monthly level. So, we created another column called \"registration_month+year\" which will enable us to compare the registration date and the last seen date by a month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Removing rows where the \"registration_month+year\" is greater than the \"last_seen\"\n",
    "remove_rows = autos[autos[\"registration_month+year\"] > autos[\"last_seen\"]].index\n",
    "autos = autos.drop(remove_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **What's Happening?** We got rid of the rows where registration_year was past last_seen in 2016."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploring The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring The Date Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-03-05    0.022936\n",
       "2016-03-06    0.013159\n",
       "2016-03-07    0.032997\n",
       "2016-03-08    0.030181\n",
       "2016-03-09    0.030160\n",
       "2016-03-10    0.029527\n",
       "2016-03-11    0.030225\n",
       "2016-03-12    0.033848\n",
       "2016-03-13    0.014360\n",
       "2016-03-14    0.033302\n",
       "2016-03-15    0.030989\n",
       "2016-03-16    0.026930\n",
       "2016-03-17    0.028479\n",
       "2016-03-18    0.011784\n",
       "2016-03-19    0.031316\n",
       "2016-03-20    0.034742\n",
       "2016-03-21    0.034000\n",
       "2016-03-22    0.029658\n",
       "2016-03-23    0.029461\n",
       "2016-03-24    0.026646\n",
       "2016-03-25    0.028326\n",
       "2016-03-26    0.029439\n",
       "2016-03-27    0.028065\n",
       "2016-03-28    0.031600\n",
       "2016-03-29    0.030945\n",
       "2016-03-30    0.030640\n",
       "2016-03-31    0.029156\n",
       "2016-04-01    0.031251\n",
       "2016-04-02    0.032844\n",
       "2016-04-03    0.035899\n",
       "2016-04-04    0.033498\n",
       "2016-04-05    0.011784\n",
       "2016-04-06    0.002815\n",
       "2016-04-07    0.001309\n",
       "NaT           0.087729\n",
       "Name: date_crawled, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autos[\"date_crawled\"].astype(str).str[:10].value_counts(normalize = True).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can see that all the listings were scrapped throughout the month of March and the beginning of April. The distribution of the number of scrapped listings a day is roughly normal. Only the 6th, 13th, and 18th have less scraped clean data for the month of March. Towards the last couple of days of April, we see a significant drop in the number of listings scrapped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-03-05    0.001004\n",
       "2016-03-06    0.003579\n",
       "2016-03-07    0.004932\n",
       "2016-03-08    0.006612\n",
       "2016-03-09    0.008751\n",
       "2016-03-10    0.009559\n",
       "2016-03-11    0.011239\n",
       "2016-03-12    0.021627\n",
       "2016-03-13    0.007878\n",
       "2016-03-14    0.011370\n",
       "2016-03-15    0.014425\n",
       "2016-03-16    0.014752\n",
       "2016-03-17    0.025009\n",
       "2016-03-18    0.006765\n",
       "2016-03-19    0.014054\n",
       "2016-03-20    0.018441\n",
       "2016-03-21    0.018615\n",
       "2016-03-22    0.018702\n",
       "2016-03-23    0.016476\n",
       "2016-03-24    0.017611\n",
       "2016-03-25    0.016957\n",
       "2016-03-26    0.015145\n",
       "2016-03-27    0.013749\n",
       "2016-03-28    0.018637\n",
       "2016-03-29    0.019881\n",
       "2016-03-30    0.022063\n",
       "2016-03-31    0.021474\n",
       "2016-04-01    0.021278\n",
       "2016-04-02    0.023089\n",
       "2016-04-03    0.022892\n",
       "2016-04-04    0.021692\n",
       "2016-04-05    0.116383\n",
       "2016-04-06    0.205661\n",
       "2016-04-07    0.121969\n",
       "NaT           0.087729\n",
       "Name: last_seen, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autos[\"last_seen\"].astype(str).str[:10].value_counts(normalize = True).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The \"last_seen\" column shows the day a listing was removed from eBay. For the purpose of this project, we will assume that the listing was taken down because the car was sold. Looking at the distribution of cars \"sold\" throughout the days, we see a disproportionate amount of cars being sold in the last couple of days. This spike in cars sold does not seem reasonable and so we will interpret this as a malfunction during the scrapping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2015-06-11    0.000022\n",
       "2015-08-10    0.000022\n",
       "2015-09-09    0.000022\n",
       "2015-11-10    0.000022\n",
       "2015-12-05    0.000022\n",
       "                ...   \n",
       "2016-04-04    0.033848\n",
       "2016-04-05    0.010650\n",
       "2016-04-06    0.002924\n",
       "2016-04-07    0.001157\n",
       "NaT           0.087729\n",
       "Name: ad_created, Length: 75, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autos[\"ad_created\"].astype(str).str[:10].value_counts(normalize = True).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We see that most of the ads were created around the same time the listings we crawled. However, there are a couple of ads that have been around since 2015, with the oldest one dating back to June - around 9 months since the last last \"date_crawled\" date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    41803.000000\n",
      "mean      2002.981485\n",
      "std          6.754847\n",
      "min       1927.000000\n",
      "25%       1999.000000\n",
      "50%       2003.000000\n",
      "75%       2008.000000\n",
      "max       2016.000000\n",
      "Name: registration_year, dtype: float64\n",
      "0    2005.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_crawled</th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>ab_test</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>registration_year</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power_ps</th>\n",
       "      <th>model</th>\n",
       "      <th>odometer_km</th>\n",
       "      <th>registration_month</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>unrepaired_damage</th>\n",
       "      <th>ad_created</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>last_seen</th>\n",
       "      <th>registration_month+year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21416</th>\n",
       "      <td>2016-03-12 08:36:21</td>\n",
       "      <td>Essex_super_six__Ford_A</td>\n",
       "      <td>16500.0</td>\n",
       "      <td>control</td>\n",
       "      <td>cabrio</td>\n",
       "      <td>1927.0</td>\n",
       "      <td>manual</td>\n",
       "      <td>40.0</td>\n",
       "      <td>other</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>petrol</td>\n",
       "      <td>ford</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-03-12</td>\n",
       "      <td>74821.0</td>\n",
       "      <td>2016-03-15 12:45:12</td>\n",
       "      <td>1927-05-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_crawled                     name    price  ab_test  \\\n",
       "21416 2016-03-12 08:36:21  Essex_super_six__Ford_A  16500.0  control   \n",
       "\n",
       "      vehicle_type  registration_year gearbox  power_ps  model  odometer_km  \\\n",
       "21416       cabrio             1927.0  manual      40.0  other       5000.0   \n",
       "\n",
       "       registration_month fuel_type brand unrepaired_damage ad_created  \\\n",
       "21416                 5.0    petrol  ford               NaN 2016-03-12   \n",
       "\n",
       "       postal_code           last_seen registration_month+year  \n",
       "21416      74821.0 2016-03-15 12:45:12              1927-05-01  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(autos[\"registration_year\"].describe())\n",
    "print(autos[\"registration_year\"].mode())\n",
    "display(autos[autos[\"registration_year\"] == 1927])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We see that the most common year a car was registered is in the year 2005, which shows, based on this data, that the average car owner keeps their car for an average of 10 years before selling it (that is if the original owner is the one selling the car). It is interesting to see that there is a car from 1927 being sold on eBay (a Cabrio Ford). There are also owners of recently registered (2016) cars who are looking to sell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring The \"price\" and \"odometer_km\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "volkswagen            8716\n",
      "bmw                   4716\n",
      "opel                  4334\n",
      "mercedes_benz         4179\n",
      "audi                  3690\n",
      "ford                  2872\n",
      "renault               1948\n",
      "peugeot               1255\n",
      "fiat                  1066\n",
      "seat                   765\n",
      "skoda                  721\n",
      "nissan                 647\n",
      "mazda                  626\n",
      "smart                  603\n",
      "citroen                576\n",
      "toyota                 559\n",
      "hyundai                430\n",
      "mini                   395\n",
      "volvo                  394\n",
      "miscellaneous_cars     382\n",
      "mitsubishi             336\n",
      "honda                  328\n",
      "kia                    318\n",
      "alfa_romeo             276\n",
      "suzuki                 253\n",
      "chevrolet              241\n",
      "porsche                184\n",
      "chrysler               145\n",
      "dacia                  116\n",
      "daihatsu                99\n",
      "jeep                    99\n",
      "subaru                  84\n",
      "land_rover              84\n",
      "saab                    73\n",
      "jaguar                  65\n",
      "daewoo                  64\n",
      "rover                   55\n",
      "trabant                 43\n",
      "lancia                  43\n",
      "lada                    23\n",
      "NaN                      0\n",
      "dtype: int64\n",
      "                      mean_price  mean_kilometerage  count\n",
      "porsche             23681.478261      112690.217391    184\n",
      "land_rover          14798.750000      126369.047619     84\n",
      "jeep                11706.606061      126717.171717     99\n",
      "jaguar              11121.107692      127307.692308     65\n",
      "mini                10786.498734       87569.620253    395\n",
      "miscellaneous_cars  10420.735602       93023.560209    382\n",
      "audi                 9467.963957      129093.495935   3690\n",
      "mercedes_benz        8492.152668      131294.568078   4179\n",
      "bmw                  8477.037956      132674.936387   4716\n",
      "chevrolet            6667.680498       99398.340249    241\n"
     ]
    }
   ],
   "source": [
    "brand_mean_prices = {}\n",
    "brand_mean_kilometerage = {}\n",
    "brand_count = {}\n",
    "brands = autos[\"brand\"].unique()\n",
    "\n",
    "for b in brands:\n",
    "    b_rows = autos[autos[\"brand\"] == b]\n",
    "    count = b_rows.shape[0]\n",
    "    mean_price = b_rows[\"price\"].mean()\n",
    "    brand_count[b] = count\n",
    "    brand_mean_prices[b] = mean_price\n",
    "    \n",
    "for b in brands:\n",
    "    b_rows = autos[autos[\"brand\"] == b]\n",
    "    mean_kilometerage = b_rows[\"odometer_km\"].mean()\n",
    "    brand_mean_kilometerage[b] = mean_kilometerage\n",
    "    \n",
    "bmp_series = pd.Series(brand_mean_prices)\n",
    "bmk_series = pd.Series(brand_mean_kilometerage)\n",
    "bc_series = pd.Series(brand_count)\n",
    "\n",
    "bmp_bmk_bc_df = pd.DataFrame(bmp_series, columns = [\"mean_price\"])\n",
    "bmp_bmk_bc_df[\"mean_kilometerage\"] = bmk_series\n",
    "bmp_bmk_bc_df[\"count\"] = bc_series\n",
    "\n",
    "print(bc_series.sort_values(ascending = False))\n",
    "\n",
    "print(bmp_bmk_bc_df.sort_values([\"mean_price\",\"mean_kilometerage\"], ascending = False).iloc[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Looking at the results for the top 10 most expensive cars brands, we see that the car brand with the highest average price is \"Porsche\" with a mean price of roughly 23,700 dollars followed by the \"land_rover\" who has an average price 37% cheaper than that of Porscheâ€™s. The most popular brand on eBay is \"BMW\" with 4716 listings. Mercedes cars are also as popular with 4179 listings. We see from the above list that 40% of the listings are German cars, which is a reasonable outcome considering that this is a German eBay car selling site. Lastly, we see that most of the mileage for the cars is quite similar, which could indicate that after around 120,000 km, people are ready to sell their cars. However, it should be noted that \"mini\" cars justifiably have the lowest mileage due to the nature and purpose of the car. The \"mini\" car is a city car that is mainly used to travel short distances, unlike the remaining cars that are built to withstand harsher activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand          model   \n",
       "volkswagen     golf        3297\n",
       "bmw            3_series    2403\n",
       "opel           corsa       1373\n",
       "volkswagen     polo        1372\n",
       "               passat      1232\n",
       "opel           astra       1196\n",
       "audi           a4          1130\n",
       "mercedes_benz  c_class     1073\n",
       "bmw            5_series    1067\n",
       "mercedes_benz  e_class      905\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autos.groupby([\"brand\", \"model\"]).size().sort_values(ascending = False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "> Throughout this Project, we have cleaned the data in various ways and have determined that \"eBay Kleineanzeigen\" is a marketplace heavily filled with German cars. Most people who sell their cars on this website tend to keep their car for roughly 10 years and sell it when the mileage reaches around 12,000 km. We discovered that Germans who buy foreign cars tend to purchase French cars such as \"Peugeot\" and \"Renault\". The most popular brand-model combination is \"Volkswagen Golf\" with an occurrence of 3368 listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".nbviewer div.output_area {\n",
       "  overflow-y: auto;\n",
       "  max-height: 400px;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".nbviewer div.output_area {\n",
    "  overflow-y: auto;\n",
    "  max-height: 400px;\n",
    "}\n",
    "</style>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
